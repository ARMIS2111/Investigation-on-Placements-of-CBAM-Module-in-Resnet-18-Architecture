{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dgifS5CO3EJf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YOZja1MN3IWC"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9w1DtQ5U3Nf8"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63cKY1_AEE2A",
    "outputId": "35d74958-48f8-4014-dc67-e7f464dd54c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "x_train = np.stack([X_train, X_train, X_train], axis=-1)\n",
    "X_test = np.stack([X_test, X_test, X_test], axis=-1)\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jTWStA03UfT",
    "outputId": "25250118-707c-4a37-8703-1266c82b369d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (60000, 28, 28)\n",
      "Shape of y_train: (60000, 10)\n",
      "Shape of X_test: (10000, 28, 28, 3)\n",
      "Shape of y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WsdH8Iz73d5x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def top_k_accuracy(predictions, labels, k=1):\n",
    "    \"\"\"\n",
    "    Calculate the top-k accuracy.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "    k: Integer, denotes top-k accuracy.\n",
    "\n",
    "    Returns:\n",
    "    accuracy: Float, top-k accuracy.\n",
    "    \"\"\"\n",
    "    sorted_indices = np.argsort(predictions, axis=1)[:, ::-1]\n",
    "    top_k_indices = sorted_indices[:, :k]\n",
    "    top_k_labels = np.take_along_axis(labels, top_k_indices, axis=1)\n",
    "    correct_predictions = np.sum(top_k_labels, axis=1)\n",
    "    accuracy = np.mean(correct_predictions)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def top_1_accuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate the top-1 accuracy.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    accuracy: Float, top-1 accuracy.\n",
    "    \"\"\"\n",
    "    return top_k_accuracy(predictions, labels, k=1)\n",
    "\n",
    "def top_5_accuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate the top-5 accuracy.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    accuracy: Float, top-5 accuracy.\n",
    "    \"\"\"\n",
    "    return top_k_accuracy(predictions, labels, k=5)\n",
    "\n",
    "def top_k_error(predictions, labels, k=1):\n",
    "    \"\"\"\n",
    "    Calculate the top-k error rate.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "    k: Integer, denotes top-k error.\n",
    "\n",
    "    Returns:\n",
    "    error: Float, top-k error rate.\n",
    "    \"\"\"\n",
    "    return 1.0 - top_k_accuracy(predictions, labels, k)\n",
    "\n",
    "def top_1_error(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate the top-1 error rate.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    error: Float, top-1 error rate.\n",
    "    \"\"\"\n",
    "    return top_k_error(predictions, labels, k=1)\n",
    "\n",
    "def top_5_error(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate the top-5 error rate.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    error: Float, top-5 error rate.\n",
    "    \"\"\"\n",
    "    return top_k_error(predictions, labels, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JIT9KvSI5upi"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRCw9pkC3V5M",
    "outputId": "5a4f975e-47f7-40ca-8a30-8b0150253a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 25s 78ms/step\n",
      "Accuracy: 0.9945\n",
      "Top-1 Accuracy: 0.9945\n",
      "Top-5 Accuracy: 0.9975\n",
      "Top-1 Error: 0.00550001859664917\n",
      "Top-5 Error: 0.002499997615814209\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       980\n",
      "           1       1.00      1.00      1.00      1135\n",
      "           2       1.00      1.00      1.00      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       1.00      0.99      1.00       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.99      0.99      1009\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      " samples avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stage2 = load_model(\"/content/drive/MyDrive/Trained Models/MNIST/resnet18_with_cbam_after_stage_2_MNIST_val_accuracy.h5\")\n",
    "y_pred = stage2.predict(X_test)\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-1 Error:\", top_1_error(y_pred_binary, y_test))\n",
    "print(\"Top-5 Error:\", top_5_error(y_pred_binary, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BprrVH4e36L4",
    "outputId": "96ec77b6-dbbb-42e3-ec4a-d367ad31fc9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 25s 78ms/step\n",
      "Accuracy: 0.9953\n",
      "Top-1 Accuracy: 0.9953\n",
      "Top-5 Accuracy: 0.9979\n",
      "Top-1 Error: 0.004700005054473877\n",
      "Top-5 Error: 0.0020999908447265625\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       1.00      1.00      1.00      1135\n",
      "           2       1.00      1.00      1.00      1032\n",
      "           3       0.99      1.00      0.99      1010\n",
      "           4       1.00      1.00      1.00       982\n",
      "           5       1.00      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       1.00      1.00      1.00       974\n",
      "           9       0.99      0.99      0.99      1009\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      " samples avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "stage3 = load_model(\"/content/drive/MyDrive/Trained Models/MNIST/resnet18_with_cbam_after_stage_3_MNIST_val_accuracy.h5\")\n",
    "y_pred = stage3.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-1 Error:\", top_1_error(y_pred_binary, y_test))\n",
    "print(\"Top-5 Error:\", top_5_error(y_pred_binary, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_u0PIkA43-yQ",
    "outputId": "f5227046-843a-4c97-d682-2121c1fdd85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 26s 82ms/step\n",
      "Accuracy: 0.9944\n",
      "Top-1 Accuracy: 0.9944\n",
      "Top-5 Accuracy: 0.9976\n",
      "Top-1 Error: 0.0055999755859375\n",
      "Top-5 Error: 0.0023999810218811035\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       980\n",
      "           1       0.99      1.00      1.00      1135\n",
      "           2       1.00      0.99      1.00      1032\n",
      "           3       0.99      1.00      0.99      1010\n",
      "           4       0.99      1.00      0.99       982\n",
      "           5       1.00      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.99      1.00      0.99      1028\n",
      "           8       0.99      1.00      1.00       974\n",
      "           9       1.00      0.99      0.99      1009\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      " samples avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "stage4 = load_model(\"/content/drive/MyDrive/Trained Models/MNIST/resnet18_with_cbam_after_stage_4_MNIST_val_accuracy.h5\")\n",
    "y_pred = stage4.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-1 Error:\", top_1_error(y_pred_binary, y_test))\n",
    "print(\"Top-5 Error:\", top_5_error(y_pred_binary, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJxkKj4p4CQk",
    "outputId": "9b207337-6bb5-4442-a584-cf99b7a4bf65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 26s 80ms/step\n",
      "Accuracy: 0.9939\n",
      "Top-1 Accuracy: 0.9939\n",
      "Top-5 Accuracy: 0.9972\n",
      "Top-1 Error: 0.006099998950958252\n",
      "Top-5 Error: 0.00279998779296875\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       1.00      1.00      1.00      1135\n",
      "           2       1.00      0.99      0.99      1032\n",
      "           3       1.00      1.00      1.00      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       1.00      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.99      1.00      0.99      1028\n",
      "           8       0.99      1.00      1.00       974\n",
      "           9       1.00      0.99      0.99      1009\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      " samples avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "stage5 = load_model(\"/content/drive/MyDrive/Trained Models/MNIST/resnet18_with_cbam_after_stage_5_MNIST_val_accuracy.h5\")\n",
    "y_pred = stage5.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-1 Error:\", top_1_error(y_pred_binary, y_test))\n",
    "print(\"Top-5 Error:\", top_5_error(y_pred_binary, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6SgMfSn4EXn",
    "outputId": "03bad991-544e-4044-fc25-21ee69d170c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 35s 94ms/step\n",
      "Accuracy: 0.9948\n",
      "Top-1 Accuracy: 0.9949\n",
      "Top-5 Accuracy: 0.9977\n",
      "Top-1 Error: 0.0051000118255615234\n",
      "Top-5 Error: 0.0023000240325927734\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       1.00      1.00      1.00      1135\n",
      "           2       0.99      1.00      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      1.00      1.00       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       1.00      1.00      1.00      1028\n",
      "           8       1.00      0.99      0.99       974\n",
      "           9       0.99      0.99      0.99      1009\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       1.00      0.99      0.99     10000\n",
      " samples avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "stageEvery = load_model(\"/content/drive/MyDrive/Trained Models/MNIST/resnet18_with_cbam_after_every_stage_MNIST_val_accuracy.h5\")\n",
    "y_pred = stageEvery.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-1 Error:\", top_1_error(y_pred_binary, y_test))\n",
    "print(\"Top-5 Error:\", top_5_error(y_pred_binary, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
