{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dgifS5CO3EJf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YOZja1MN3IWC"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9w1DtQ5U3Nf8"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63cKY1_AEE2A",
    "outputId": "dbd667bb-0910-4149-e20b-ebf4a082e29b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(X_train, y_train), (X_test,y_test) = cifar10.load_data()\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)\n",
    "X_train = X_train * 1.0/255\n",
    "X_test = X_test * 1.0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jTWStA03UfT",
    "outputId": "812cab81-3f51-4008-a5e7-bf9810cbe563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (50000, 32, 32, 3)\n",
      "Shape of y_train: (50000, 10)\n",
      "Shape of X_test: (10000, 32, 32, 3)\n",
      "Shape of y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WsdH8Iz73d5x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def top_k_accuracy(predictions, labels, k=1):\n",
    "    \"\"\"\n",
    "    Calculate the top-k accuracy.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "    k: Integer, denotes top-k accuracy.\n",
    "\n",
    "    Returns:\n",
    "    accuracy: Float, top-k accuracy.\n",
    "    \"\"\"\n",
    "    sorted_indices = np.argsort(predictions, axis=1)[:, ::-1]\n",
    "    top_k_indices = sorted_indices[:, :k]\n",
    "    top_k_labels = np.take_along_axis(labels, top_k_indices, axis=1)\n",
    "    correct_predictions = np.sum(top_k_labels, axis=1)\n",
    "    accuracy = np.mean(correct_predictions)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def top_1_accuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate the top-1 accuracy.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    accuracy: Float, top-1 accuracy.\n",
    "    \"\"\"\n",
    "    return top_k_accuracy(predictions, labels, k=1)\n",
    "\n",
    "def top_5_accuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate the top-5 accuracy.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    accuracy: Float, top-5 accuracy.\n",
    "    \"\"\"\n",
    "    return top_k_accuracy(predictions, labels, k=5)\n",
    "\n",
    "def top_k_error(predictions, labels, k=1):\n",
    "    \"\"\"\n",
    "    Calculate the top-k error rate.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "    k: Integer, denotes top-k error.\n",
    "\n",
    "    Returns:\n",
    "    error: Float, top-k error rate.\n",
    "    \"\"\"\n",
    "    return 1.0 - top_k_accuracy(predictions, labels, k)\n",
    "\n",
    "def top_1_error(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate the top-1 error rate.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    error: Float, top-1 error rate.\n",
    "    \"\"\"\n",
    "    return top_k_error(predictions, labels, k=1)\n",
    "\n",
    "def top_5_error(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate the top-5 error rate.\n",
    "\n",
    "    Args:\n",
    "    predictions: Array-like, predicted binary values (0 or 1).\n",
    "    labels: Array-like, ground truth binary values (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    error: Float, top-5 error rate.\n",
    "    \"\"\"\n",
    "    return top_k_error(predictions, labels, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JIT9KvSI5upi"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRCw9pkC3V5M",
    "outputId": "969b74ac-41b6-42d1-f952-27559fb27747"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 29s 77ms/step\n",
      "Accuracy: 0.8206\n",
      "Top-1 Accuracy: 0.8207\n",
      "Top-5 Accuracy: 0.8752\n",
      "Top-1 Error: 0.17930001020431519\n",
      "Top-5 Error: 0.12480002641677856\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85      1000\n",
      "           1       0.92      0.91      0.92      1000\n",
      "           2       0.77      0.74      0.76      1000\n",
      "           3       0.67      0.65      0.66      1000\n",
      "           4       0.79      0.79      0.79      1000\n",
      "           5       0.75      0.72      0.74      1000\n",
      "           6       0.84      0.87      0.86      1000\n",
      "           7       0.87      0.86      0.86      1000\n",
      "           8       0.89      0.91      0.90      1000\n",
      "           9       0.89      0.89      0.89      1000\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      " samples avg       0.82      0.82      0.82     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "stage2 = load_model(\"/content/drive/MyDrive/Trained Models/CIFAR10/resnet18_with_cbam_after_stage_2_CIFAR10_val_accuracy.h5\")\n",
    "y_pred = stage2.predict(X_test)\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-1 Error:\", top_1_error(y_pred_binary, y_test))\n",
    "print(\"Top-5 Error:\", top_5_error(y_pred_binary, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BprrVH4e36L4",
    "outputId": "87008270-92e4-44a5-f1fc-47dd0108ba88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 24s 73ms/step\n",
      "Accuracy: 0.8266\n",
      "Top-1 Accuracy: 0.8266\n",
      "Top-5 Accuracy: 0.8793\n",
      "Top-1 Error: 0.17339998483657837\n",
      "Top-5 Error: 0.12070000171661377\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1000\n",
      "           1       0.92      0.92      0.92      1000\n",
      "           2       0.76      0.74      0.75      1000\n",
      "           3       0.68      0.67      0.68      1000\n",
      "           4       0.78      0.81      0.79      1000\n",
      "           5       0.76      0.76      0.76      1000\n",
      "           6       0.85      0.88      0.87      1000\n",
      "           7       0.88      0.85      0.87      1000\n",
      "           8       0.90      0.91      0.90      1000\n",
      "           9       0.90      0.89      0.90      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      " samples avg       0.83      0.83      0.83     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "stage3 = load_model(\"/content/drive/MyDrive/Trained Models/CIFAR10/resnet18_with_cbam_after_stage_3_CIFAR10_val_accuracy.h5\")\n",
    "y_pred = stage3.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-1 Error:\", top_1_error(y_pred_binary, y_test))\n",
    "print(\"Top-5 Error:\", top_5_error(y_pred_binary, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_u0PIkA43-yQ",
    "outputId": "9544f309-1cf9-48e4-8c87-0e88e8db82f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 24s 73ms/step\n",
      "Accuracy: 0.8376\n",
      "Top-1 Accuracy: 0.8378\n",
      "Top-5 Accuracy: 0.8855\n",
      "Top-1 Error: 0.1621999740600586\n",
      "Top-5 Error: 0.11449998617172241\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      1000\n",
      "           1       0.93      0.93      0.93      1000\n",
      "           2       0.79      0.76      0.77      1000\n",
      "           3       0.70      0.68      0.69      1000\n",
      "           4       0.80      0.80      0.80      1000\n",
      "           5       0.77      0.77      0.77      1000\n",
      "           6       0.86      0.88      0.87      1000\n",
      "           7       0.87      0.87      0.87      1000\n",
      "           8       0.91      0.91      0.91      1000\n",
      "           9       0.91      0.90      0.91      1000\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      " samples avg       0.84      0.84      0.84     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "stage4 = load_model(\"/content/drive/MyDrive/Trained Models/CIFAR10/resnet18_with_cbam_after_stage_4_CIFAR10_val_accuracy.h5\")\n",
    "y_pred = stage4.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-1 Error:\", top_1_error(y_pred_binary, y_test))\n",
    "print(\"Top-5 Error:\", top_5_error(y_pred_binary, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJxkKj4p4CQk",
    "outputId": "2f6a30d8-fb90-4b9a-e493-07e645096944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 23s 71ms/step\n",
      "Accuracy: 0.8261\n",
      "Top-1 Accuracy: 0.8261\n",
      "Top-5 Accuracy: 0.8794\n",
      "Top-1 Error: 0.17390000820159912\n",
      "Top-5 Error: 0.12059998512268066\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      1000\n",
      "           1       0.91      0.92      0.91      1000\n",
      "           2       0.77      0.74      0.76      1000\n",
      "           3       0.68      0.66      0.67      1000\n",
      "           4       0.79      0.82      0.80      1000\n",
      "           5       0.75      0.76      0.75      1000\n",
      "           6       0.85      0.88      0.86      1000\n",
      "           7       0.89      0.85      0.87      1000\n",
      "           8       0.89      0.91      0.90      1000\n",
      "           9       0.90      0.88      0.89      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      " samples avg       0.83      0.83      0.83     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "stage5 = load_model(\"/content/drive/MyDrive/Trained Models/CIFAR10/resnet18_with_cbam_after_stage_5_CIFAR10_val_accuracy.h5\")\n",
    "y_pred = stage5.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-1 Error:\", top_1_error(y_pred_binary, y_test))\n",
    "print(\"Top-5 Error:\", top_5_error(y_pred_binary, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6SgMfSn4EXn",
    "outputId": "9f4c501d-847a-45f4-982c-fc59a79510a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 29s 90ms/step\n",
      "Accuracy: 0.8342\n",
      "Top-1 Accuracy: 0.8344\n",
      "Top-5 Accuracy: 0.885\n",
      "Top-1 Error: 0.1656000018119812\n",
      "Top-5 Error: 0.11500000953674316\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      1000\n",
      "           1       0.91      0.93      0.92      1000\n",
      "           2       0.78      0.75      0.77      1000\n",
      "           3       0.69      0.69      0.69      1000\n",
      "           4       0.82      0.81      0.81      1000\n",
      "           5       0.78      0.75      0.77      1000\n",
      "           6       0.87      0.88      0.87      1000\n",
      "           7       0.86      0.87      0.87      1000\n",
      "           8       0.90      0.91      0.91      1000\n",
      "           9       0.91      0.89      0.90      1000\n",
      "\n",
      "   micro avg       0.84      0.83      0.84     10000\n",
      "   macro avg       0.84      0.83      0.84     10000\n",
      "weighted avg       0.84      0.83      0.84     10000\n",
      " samples avg       0.83      0.83      0.83     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "stageEvery = load_model(\"/content/drive/MyDrive/Trained Models/CIFAR10/resnet18_with_cbam_after_every_stage_CIFAR10_val_accuracy.h5\")\n",
    "y_pred = stageEvery.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy(y_pred_binary, y_test))\n",
    "print(\"Top-1 Error:\", top_1_error(y_pred_binary, y_test))\n",
    "print(\"Top-5 Error:\", top_5_error(y_pred_binary, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yZ8w-RH8s6s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
