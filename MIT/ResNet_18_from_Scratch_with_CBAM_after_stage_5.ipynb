{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJwDcJgXtfJX"
   },
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yAXD667qtfJY"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import h5py\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Multiply, Lambda, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib.pyplot import imshow\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsGJZgIRl8F5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FsxRl6H1tfJZ"
   },
   "outputs": [],
   "source": [
    "def channel_attention(x, ratio= 8):\n",
    "    b, _, _, channel = x.shape\n",
    "    # MLP\n",
    "    l1 = Dense(channel//ratio, activation = \"relu\", use_bias = False)\n",
    "    l2 = Dense(channel, use_bias = False)\n",
    "\n",
    "    # Apply Global Average Pooling\n",
    "    x1 = GlobalAveragePooling2D()(x)\n",
    "    x1 = l1(x1)\n",
    "    x1 = l2(x1)\n",
    "\n",
    "    # Apply Max Pooling\n",
    "    x2 = GlobalMaxPooling2D()(x)\n",
    "    x2 = l1(x2)\n",
    "    x2 = l2(x2)\n",
    "\n",
    "    # Add and apply Sigmoid activation function\n",
    "    features = x1 + x2\n",
    "    features = Activation(\"sigmoid\")(features)\n",
    "    features = Multiply()([x, features])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1OYvqGttfJa"
   },
   "outputs": [],
   "source": [
    "def spatial_attention(x):\n",
    "    # Apply Average Pooling\n",
    "    x1 = tf.reduce_mean(x, axis = -1)\n",
    "    x1 = tf.expand_dims(x1, axis = -1)\n",
    "\n",
    "    # Apply Max Pooling\n",
    "    x2 = tf.reduce_mean(x, axis = -1)\n",
    "    x2 = tf.expand_dims(x2, axis = -1)\n",
    "\n",
    "    # Concatenate\n",
    "    features = Concatenate()([x1, x2])\n",
    "\n",
    "    # Convolution Layer\n",
    "    features = Conv2D(1, kernel_size = 7, padding='same', activation='sigmoid')(features)\n",
    "    features = Multiply()([x, features])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJmAH6QmtfJa"
   },
   "outputs": [],
   "source": [
    "def cbam(x):\n",
    "    channel_attention_fm = channel_attention(x)\n",
    "    spatial_attention_fm = spatial_attention(channel_attention_fm)\n",
    "    return x+spatial_attention_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAPWM9CQtfJa"
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : tensor\n",
    "        input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f : integer\n",
    "        specifying the shape of the middle CONV's window for the main path\n",
    "    filters : list\n",
    "        python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage : integer\n",
    "        used to name the layers, depending on their position in the network\n",
    "    block : str\n",
    "        used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : tensor\n",
    "        output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. we'll need this later to add back to the main path.\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMRjelhotfJb"
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : tensor\n",
    "        input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f : integer\n",
    "        specifying the shape of the middle CONV's window for the main path\n",
    "    filters : list\n",
    "        python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage : integer\n",
    "        used to name the layers, depending on their position in the network\n",
    "    block : str\n",
    "        used to name the layers, depending on their position in the network\n",
    "    s : integer, optional\n",
    "        Integer, specifying the stride to be used. The default is 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : tensor\n",
    "        output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZfIPl-pttfJc"
   },
   "outputs": [],
   "source": [
    "def ResNet18(input_shape, outputClasses):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet18 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : tuple, optional\n",
    "        shape of the input image.\n",
    "    outputClasses : integer, optional\n",
    "        number of classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : object\n",
    "        a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    X = cbam(X)\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(outputClasses, activation='softmax', name='fc' + str(outputClasses),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet18')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvqcII1OtfJc"
   },
   "source": [
    "<h1><center> Implementation </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_zNBg7wtfJc"
   },
   "source": [
    "### Loading and Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeBfye78t1QM",
    "outputId": "1437d82f-fa91-4198-d1b7-9e98b24ec326"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03vb85M_Xw-b",
    "outputId": "6a04ad9a-2b39-4584-da1f-035a0d872e9d"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/Datasets/MITIndoorDataset/indoor_CVPR_09_augmented.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnJ8W2S6WaqP"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlsgzQxpWzLU"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfkFZWtosfUo"
   },
   "outputs": [],
   "source": [
    "DATADIR = \"/content/content/drive/MyDrive/Datasets/MITIndoorDataset/indoor_CVPR_09_augmented\"\n",
    "CATEGORIES = os.listdir(DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ya0BjakVQGQb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pUAP2O2sR2w"
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path, test_size=0.2, random_state=42):\n",
    "    categories = os.listdir(dataset_path)\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            images = os.listdir(category_path)\n",
    "            for image in images:\n",
    "                image_path = os.path.join(category_path, image)\n",
    "                img = Image.open(image_path)\n",
    "                img = np.array(img)\n",
    "                X.append(img)\n",
    "                y.append(category)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zeXJQRMbs4j8",
    "outputId": "489031ba-c81b-4aa5-8123-51932c28f65f"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = load_dataset(DATADIR)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXKpHsE5jmfG"
   },
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "\n",
    "# # Assuming your target labels are currently in a list called target_labels\n",
    "# target_labels = CATEGORIES  # Fill this with your actual target labels\n",
    "\n",
    "# # Convert target labels to one-hot encoded format\n",
    "# one_hot_target = to_categorical(target_labels, num_classes=67)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Assuming your target labels are currently stored in a list called target_labels\n",
    "target_labels = CATEGORIES  # Fill this with your actual target labels\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and transform target labels\n",
    "encoded_labels_train = label_encoder.fit_transform(y_train)\n",
    "encoded_labels_test = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Convert encoded labels to one-hot encoded format\n",
    "y_train = to_categorical(encoded_labels_train, num_classes=len(label_encoder.classes_))\n",
    "y_test = to_categorical(encoded_labels_test, num_classes=len(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTDOmk66k5M_",
    "outputId": "15969046-9d9f-4ceb-884b-27fb402f7226"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyCNvU0StfJd"
   },
   "source": [
    "### Model creation and compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RcAoyRdtfJd"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    factor=0.6,\n",
    "    min_lr=1e-6)\n",
    "\n",
    "checkpoint_filepath1 = '/content/drive/MyDrive/Trained Models/resnet18_with_cbam_after_stage_5_MIT_val_accuracy.h5'\n",
    "checkpoint1 = ModelCheckpoint(filepath=checkpoint_filepath1,\n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True,\n",
    "                             mode='max',\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80N-UMrTtfJe",
    "outputId": "b14ddb93-62ec-4c2f-c483-cd6a9f226b7b"
   },
   "outputs": [],
   "source": [
    "resnet18 = ResNet18(input_shape=(224, 224, 3), outputClasses=67)\n",
    "resnet18.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "resnet18.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvfIl2w5YDnH"
   },
   "outputs": [],
   "source": [
    "num_epochs = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zp896inxtfJe",
    "outputId": "d35abce8-ad5e-41ea-f6a9-e458723e9a25"
   },
   "outputs": [],
   "source": [
    "resnet_teacher_history = resnet18.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 32,\n",
    "    epochs=num_epochs,\n",
    "    validation_split = 0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[learning_rate_reduction, checkpoint1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
